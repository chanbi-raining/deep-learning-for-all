{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H(x) = Wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# Variable = the variables that tensorflow uses = trainable variable\n",
    "# random_normal = assign a shape\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight') # rank 1 \n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# Our hypothesis XW + b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_15:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# reduce_mean = averaging a tensor\n",
    "t = [1., 2., 3., 4.]\n",
    "print(tf.reduce_mean(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost) # name of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6363976 [0.35665607] [0.68629634]\n",
      "100 0.0584697 [0.71915627] [0.638418]\n",
      "200 0.036130715 [0.779233] [0.5018554]\n",
      "300 0.022326587 [0.826457] [0.39450404]\n",
      "400 0.013796474 [0.8635794] [0.3101161]\n",
      "500 0.008525387 [0.89276093] [0.24377961]\n",
      "600 0.005268168 [0.9157003] [0.19163293]\n",
      "700 0.003255402 [0.9337328] [0.15064092]\n",
      "800 0.0020116393 [0.9479079] [0.1184174]\n",
      "900 0.0012430701 [0.9590509] [0.09308688]\n",
      "1000 0.0007681437 [0.9678103] [0.07317479]\n",
      "1100 0.00047466633 [0.9746959] [0.05752206]\n",
      "1200 0.00029331457 [0.9801088] [0.04521759]\n",
      "1300 0.000181249 [0.9843636] [0.0355451]\n",
      "1400 0.000112002046 [0.98770833] [0.02794174]\n",
      "1500 6.921111e-05 [0.99033767] [0.02196488]\n",
      "1600 4.2768133e-05 [0.9924045] [0.01726629]\n",
      "1700 2.6427486e-05 [0.9940293] [0.01357287]\n",
      "1800 1.6331174e-05 [0.9953065] [0.01066953]\n",
      "1900 1.0091315e-05 [0.9963105] [0.00838722]\n",
      "2000 6.2358345e-06 [0.99709964] [0.00659314]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.46007124 [2.5825417] [-0.6815191]\n",
      "100 0.054728433 [2.2717097] [-0.617655]\n",
      "200 0.033818845 [2.2135873] [-0.48553407]\n",
      "300 0.020898009 [2.1678994] [-0.3816741]\n",
      "400 0.012913697 [2.131984] [-0.30003032]\n",
      "500 0.007979895 [2.1037514] [-0.23585138]\n",
      "600 0.0049311086 [2.0815585] [-0.18540071]\n",
      "700 0.003047116 [2.064112] [-0.14574166]\n",
      "800 0.001882926 [2.0503979] [-0.11456631]\n",
      "900 0.0011635629 [2.0396178] [-0.09006036]\n",
      "1000 0.0007190006 [2.0311427] [-0.07079527]\n",
      "1100 0.0004442936 [2.0244813] [-0.05565145]\n",
      "1200 0.00027454842 [2.0192444] [-0.04374696]\n",
      "1300 0.00016964933 [2.0151277] [-0.03438885]\n",
      "1400 0.00010483436 [2.0118918] [-0.0270328]\n",
      "1500 6.478234e-05 [2.0093482] [-0.02125024]\n",
      "1600 4.0031726e-05 [2.0073485] [-0.01670471]\n",
      "1700 2.4737621e-05 [2.0057766] [-0.01313155]\n",
      "1800 1.5287755e-05 [2.0045414] [-0.01032305]\n",
      "1900 9.447863e-06 [2.00357] [-0.00811526]\n",
      "2000 5.8391597e-06 [2.0028067] [-0.00637975]\n"
     ]
    }
   ],
   "source": [
    "# X and Y = placeholders for a tensor that will always be fed using feed_dict\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict = {X: [1, 2, 3], Y: [2, 4, 6]})\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28.769016 [-0.31632537] [0.01870855]\n",
      "100 0.040964406 [1.1314019] [0.6255976]\n",
      "200 0.020808555 [1.0936525] [0.7618849]\n",
      "300 0.01057006 [1.0667478] [0.8590192]\n",
      "400 0.005369242 [1.0475724] [0.9282485]\n",
      "500 0.0027274222 [1.0339057] [0.9775894]\n",
      "600 0.0013854298 [1.0241652] [1.012756]\n",
      "700 0.0007037447 [1.0172229] [1.0378199]\n",
      "800 0.0003574779 [1.0122751] [1.0556831]\n",
      "900 0.00018158517 [1.0087485] [1.0684148]\n",
      "1000 9.223276e-05 [1.0062351] [1.0774893]\n",
      "1100 4.6848272e-05 [1.0044436] [1.0839568]\n",
      "1200 2.3798008e-05 [1.0031672] [1.0885656]\n",
      "1300 1.2088965e-05 [1.0022573] [1.0918504]\n",
      "1400 6.1407336e-06 [1.001609] [1.0941913]\n",
      "1500 3.1202658e-06 [1.0011468] [1.0958594]\n",
      "1600 1.5854124e-06 [1.0008175] [1.0970486]\n",
      "1700 8.0560403e-07 [1.0005827] [1.0978961]\n",
      "1800 4.0943482e-07 [1.0004154] [1.0985001]\n",
      "1900 2.080294e-07 [1.0002961] [1.0989308]\n",
      "2000 1.0574924e-07 [1.0002114] [1.0992376]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None]) # 1d array and any number of values possible\n",
    "\n",
    "hypothesis = X * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# fit the line with new training data\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], \\\n",
    "                                         feed_dict = {X: [1, 2, 3, 4, 5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1003404]\n",
      "[3.5997286]\n",
      "[2.599484 4.599973]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict = {X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict = {X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict = {X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, Module, MSELoss\n",
    "from torch.optim import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables** : record the operations happened to the Tensor → `torch.autograd.Variable`\n",
    "**Optimizer** → `torch.optim` here I used *Stochastic Gradient Descent*  \n",
    "**Linear transformation** → `torch.nn.Linear(in_features, out_features, bias = True)`\n",
    "-  in_features : size of each input sample\n",
    "- out_features : size of each output sample  \n",
    "\n",
    "\n",
    "**Mean squared error** → `torch.nn.MSELoss`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.2100) linear.weight tensor([[1.0440]])linear.bias tensor([0.0220])\n",
      "100 tensor(0.0753) linear.weight tensor([[1.3179]])linear.bias tensor([0.3772])\n",
      "200 tensor(0.0465) linear.weight tensor([[1.2499]])linear.bias tensor([0.5318])\n",
      "300 tensor(0.0288) linear.weight tensor([[1.1965]])linear.bias tensor([0.6534])\n",
      "400 tensor(0.0178) linear.weight tensor([[1.1544]])linear.bias tensor([0.7489])\n",
      "500 tensor(0.0110) linear.weight tensor([[1.1214]])linear.bias tensor([0.8240])\n",
      "600 tensor(0.0068) linear.weight tensor([[1.0954]])linear.bias tensor([0.8831])\n",
      "700 tensor(0.0042) linear.weight tensor([[1.0750]])linear.bias tensor([0.9295])\n",
      "800 tensor(0.0026) linear.weight tensor([[1.0590]])linear.bias tensor([0.9659])\n",
      "900 tensor(0.0016) linear.weight tensor([[1.0464]])linear.bias tensor([0.9946])\n",
      "1000 tensor(0.0010) linear.weight tensor([[1.0364]])linear.bias tensor([1.0172])\n",
      "1100 tensor(0.0006) linear.weight tensor([[1.0286]])linear.bias tensor([1.0349])\n",
      "1200 tensor(0.0004) linear.weight tensor([[1.0225]])linear.bias tensor([1.0488])\n",
      "1300 tensor(0.0002) linear.weight tensor([[1.0177]])linear.bias tensor([1.0598])\n",
      "1400 tensor(0.0001) linear.weight tensor([[1.0139]])linear.bias tensor([1.0684])\n",
      "1500 tensor(0.0001) linear.weight tensor([[1.0109]])linear.bias tensor([1.0751])\n",
      "1600 tensor(0.0001) linear.weight tensor([[1.0086]])linear.bias tensor([1.0805])\n",
      "1700 tensor(0.0000) linear.weight tensor([[1.0068]])linear.bias tensor([1.0846])\n",
      "1800 tensor(0.0000) linear.weight tensor([[1.0053]])linear.bias tensor([1.0879])\n",
      "1900 tensor(0.0000) linear.weight tensor([[1.0042]])linear.bias tensor([1.0905])\n",
      "2000 tensor(8.0311e-06) linear.weight tensor([[1.0033]])linear.bias tensor([1.0925])\n"
     ]
    }
   ],
   "source": [
    "# define criterion - loss function\n",
    "criterion = MSELoss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "x_train = torch.from_numpy(np.array([[1.], [2.], [3.]], dtype = np.float32))\n",
    "y_train = torch.from_numpy(np.array([[2.1], [3.1], [4.1]], dtype = np.float32))\n",
    "\n",
    "for epoch in range(2001):\n",
    "    inputs = Variable(x_train)\n",
    "    target = Variable(y_train)\n",
    "    \n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, target)\n",
    "    \n",
    "    # 'zeroing' the gradients of the network\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    # backpropagation\n",
    "    loss.backward() \n",
    "        \n",
    "    # make a step in the right direction\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, loss.data[0], end = ' ')\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data, end = '')\n",
    "        print()\n",
    "    \n",
    "    model.eval()\n",
    "    predict = model(Variable(x_train)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.1090], grad_fn=<ThAddBackward>)\n",
      "tensor([7.5135], grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "print( model(Variable(torch.Tensor([5]))))\n",
    "print( model(Variable(torch.Tensor([6.4]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
