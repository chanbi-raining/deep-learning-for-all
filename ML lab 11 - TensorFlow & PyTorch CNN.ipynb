{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "## TensorFlow\n",
    "### CNN Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b5aa7d5a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],[[4],[5],[6]], [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter: 2, 2, 1, 1 ((size, size), color, # of filters)\n",
    "# mulitplication + addition\n",
    "\n",
    "weight = tf.constant([[[[1.]], [[1.]]], [[[1.]], [[1.]]]])\n",
    "print('weight.shape', weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAC7CAYAAADPLLrPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACWpJREFUeJzt3X2IZXUdx/H3J1enRavdWmuX9WGNFskeIB1HRZAlWdBFXCGD9Y98QBkQpQcK0gKDILH+KJINY0uxiVDDYttkY1G0NErZUdaHdVmdJHBxwRxzt0Vbmfr2xz3V9Xpnv7N7fvO7MzufF1zmnHt+M9/fZfhw7jnn3u9RRGBm03vPoCdgNtc5JGYJh8Qs4ZCYJRwSs4RDYpZoFRJJH5T0oKQXm59Lpxn3L0k7mseWNjXNalOb6ySSvge8HhG3SboJWBoRX+8z7kBEnNBinmYD0zYku4E1EbFX0grg9xFxep9xDonNW22PST4SEXsBmp8fnmbceyWNS3pc0mUta5pVtSgbIOkhYHmfTd88jDqnRMQrkj4KPCzp2Yj4S59ao8Bos3zW0NDQYZSYu44//vhBT6GYycnJQU+hpNci4sRsUJW3Wz2/czfwQETcf6hxixcvjlWrVh3x3OaSkZGRQU+hmLGxsUFPoaQnI2I4G9T27dYW4Kpm+SrgN70DJC2VNNQsLwPOB55vWdesmrYhuQ1YK+lFYG2zjqRhST9txnwcGJf0NPAIcFtEOCQ2b6THJIcSEZPAhX2eHweua5b/BHyqTR2zQfIVd7OEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzRJGQSLpI0m5JE02Tut7tQ5Lua7Y/IWlVibpmNbQOiaRjgB8BFwNnAFdIOqNn2LXA3yPiY8APgO+2rWtWS4k9yQgwEREvRcTbwL3A+p4x64GfNcv3AxdKUoHaZrOuREhWAi93re9pnus7JiKmgH3Ah3r/kKTRptPj+NTUVIGpmbVXIiT99gi9He9mMoaI2BQRwxExvGhRq0YuZsWUCMke4OSu9ZOAV6YbI2kR8AHg9QK1zWZdiZBsB1ZLOk3SccAGOp0du3V3erwceDh8b2ybJ1q/p4mIKUk3AtuAY4C7ImKnpG8D4xGxBbgT+LmkCTp7kA1t65rVUuSNf0RsBbb2PHdL1/I/gc+XqGVWm6+4myUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCxRqznd1ZL+JmlH87iuRF2zGlp/M7GrOd1aOg0ftkvaEhHP9wy9LyJubFvPrLZazenM5q0S33Hv15zunD7jPifpAuAF4CsR8XLvAEmjwCjA8uXLGRsbKzC9wTv77LMHPYVi9u/fP+gpFLN58+YZjavVnO63wKqI+DTwEP9vefrOX+pqTrdkyZICUzNrr0pzuoiYjIiDzepPgLMK1DWrokpzOkkrulYvBXYVqGtWRa3mdF+UdCkwRac53dVt65rVUqs53c3AzSVqmdXmK+5mCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExS5RqTneXpFclPTfNdkm6vWle94ykM0vUNauh1J7kbuCiQ2y/GFjdPEaBOwrVNZt1RUISEY/S+e76dNYDY9HxOLCkpzmE2ZxV65ikXwO7lZVqm7VSKyQzaWCHpFFJ45LG33jjjQrTMsvVCknawA7cwdHmploh2QJc2ZzlOhfYFxF7K9U2a6VI3y1J9wBrgGWS9gDfAo4FiIgf0+nJtQ6YAN4ErilR16yGUs3prki2B3BDiVpmtfmKu1nCITFLOCRmCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZolYHxzWS9kna0TxuKVHXrIYiX9+l08FxIzB2iDGPRcQlheqZVVOrg6PZvFVqTzIT50l6mk6/ra9FxM7eAZJG6fQKZvHixdx6660Vpzd7Vq48eppVbt68edBTqK5WSJ4CTo2IA5LWAZvpNM9+h4jYBGwCWLp06bs6PJoNQpWzWxGxPyIONMtbgWMlLatR26ytKiGRtFySmuWRpu5kjdpmbdXq4Hg5cL2kKeAtYEPTsM5szqvVwXEjnVPEZvOOr7ibJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzhENilnBIzBIOiVnCITFLOCRmCYfELNE6JJJOlvSIpF2Sdkr6Up8xknS7pAlJz0g6s21ds1pKfDNxCvhqRDwl6X3Ak5IejIjnu8ZcTKc7ymrgHOCO5qfZnNd6TxIReyPiqWb5H8AuoLfR1HpgLDoeB5ZIWtG2tlkNRY9JJK0CPgM80bNpJfBy1/oe3h0kJI1KGpc0fvDgwZJTMztixUIi6QTgV8CXI2J/7+Y+v/KubikRsSkihiNieGhoqNTUzFop1VX+WDoB+UVE/LrPkD3AyV3rJ9Fpd2o255U4uyXgTmBXRHx/mmFbgCubs1znAvsiYm/b2mY1lDi7dT7wBeBZSTua574BnAL/a063FVgHTABvAtcUqGtWReuQRMQf6X/M0T0mgBva1jIbBF9xN0s4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzhENilnBIzBIOiVmiVnO6NZL2SdrRPG5pW9esllrN6QAei4hLCtQzq6pWczqzeatWczqA8yQ9Lel3kj5Rsq7ZbFKnR0OBP9RpTvcH4Du9vbckvR/4d0QckLQO+GFErO7zN0aB0Wb1dGB3kckd2jLgtQp1ajhaXkut13FqRJyYDSoSkqY53QPAtkP03uoe/1dgOCIG/g+VNB4Rw4OeRwlHy2uZa6+jSnM6ScubcUgaaepOtq1tVkOt5nSXA9dLmgLeAjZEqfd5ZrOsVnO6jcDGtrVmyaZBT6Cgo+W1zKnXUezA3exo5Y+lmCUWbEgkXSRpd3Mfx5sGPZ8jJekuSa9Kem7Qc2lrJh9xGoQF+XZL0jHAC8BaOvdO2Q5c0eejNHOepAuAA3Rut/fJQc+njeYWgSu6P+IEXDbo/8tC3ZOMABMR8VJEvA3cS+e+jvNORDwKvD7oeZQwVz/itFBDMqN7ONrgJB9xqmqhhmRG93C0wUjuv1ndQg2J7+E4R83g/pvVLdSQbAdWSzpN0nHABjr3dbQBmuH9N6tbkCGJiCngRmAbnYPDX0bEzsHO6shIugf4M3C6pD2Srh30nFr470ecPtv1LdZ1g57UgjwFbHY4FuSexOxwOCRmCYfELOGQmCUcErOEQ2KWcEjMEg6JWeI/TTEFLVhDkXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output image size SAME as the input\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 filters (2,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAACFCAYAAAB7VhJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAB29JREFUeJzt3cFrXXUaxvHnmSbtohoaOrOQa5k4VITulNtsBCmuOm7c6iLdCF0FFGbjH1HcdVOwlIAoQ3XhQpBZWGRArHeKA+0Eh47tYFBwWlsiXVQC7yxyGcJYyYk55/zO+7vfDwRy08s5z+0THk4uNzeOCAEA8vhN6QAAgL1huAEgGYYbAJJhuAEgGYYbAJJhuAEgGYYbAJJhuAEgGYYbAJKZ6+Sgc3MxPz/fxaEbO3z4cNHzS9Ldu3dLR1BEuK1j0eu22npdXFyM0WjU1uF+lQcPHhQ9vyQdPXq06Plv376tO3fuNOq1k+Gen5/X0tJSF4dubHl5uej5JWltba10hFbR67baeh2NRrp8+XLRDFevXi16fkk6c+ZM0fOPx+PG9+WpEgBIhuEGgGQYbgBIhuEGgGQYbgBIhuEGgGQYbgBIhuEGgGQYbgBIhuEGgGQYbgBIptFw2z5t+yvbN22/2XUo9INe60Sv9dt1uG0fkHRe0h8lnZD0qu0TXQdDt+i1TvQ6G5pccS9LuhkRX0fET5Lek/Ryt7HQA3qtE73OgCbDPZL0zY7bG9OvITd6rRO9zoAmw/2oN/aOn93JPmt7YnuytbW1/2ToGr3Wac+93rt3r4dYaFOT4d6QdGzH7Sclffv/d4qICxExjojx3Fwnf58B7aLXOu2518XFxd7CoR1NhvsLSU/bfsr2QUmvSPqw21joAb3WiV5nwK6XUBGxZXtV0seSDki6GBE3Ok+GTtFrneh1NjT62TciPpL0UcdZ0DN6rRO91o/fnASAZBhuAEiG4QaAZBhuAEiG4QaAZBhuAEiG4QaAZBhuAEiG4QaAZBhuAEiG4QaAZDp5n86lpSWtra11cejGTp48WfT8krS5uVn0/FeuXGn1ePS6rbZeb926pZWVlVaPuVeTyaTo+SVpYWGh6Pnv37/f+L5ccQNAMgw3ACTDcANAMgw3ACTDcANAMgw3ACTDcANAMgw3ACTDcANAMgw3ACTDcANAMgw3ACSz63Dbvmj7e9vX+wiEftBrvei2fk2uuC9JOt1xDvTvkui1VpdEt1Xbdbgj4lNJP/SQBT2i13rRbf14jhsAkmltuG2ftT2xPdnLG4Jj2Oi1Tjt73draKh0He9TacEfEhYgYR8T4yJEjbR0WhdFrnXb2OjfXyR/CQod4qgQAkmnycsB3JX0m6RnbG7Zf6z4Wukav9aLb+u36M1JEvNpHEPSLXutFt/XjqRIASIbhBoBkGG4ASIbhBoBkGG4ASIbhBoBkGG4ASIbhBoBkGG4ASIbhBoBkGG4ASMYR0fpBFxcX49SpU60fdy9Go1HR80vS+fPnS0dQRLitY9Hrttp6PX78eJw7d66tw/0qGxsbRc8vSaurq0XPPx6PNZlMGvXKFTcAJMNwA0AyDDcAJMNwA0AyDDcAJMNwA0AyDDcAJMNwA0AyDDcAJMNwA0AyDDcAJMNwA0Ayuw637WO2P7G9bvuG7df7CIZu0Wud6HU2zDW4z5akP0XENduPS/qb7b9ExD86zoZu0Wud6HUG7HrFHRHfRcS16ec/SlqXVP69NbEv9Fonep0Ne3qO2/aSpGclff6Ifztre2J78vDhw3bSoRf0WqemvW5ubvYdDfvUeLhtPybpfUlvRMTPmo6ICxExjojxoUOH2syIDtFrnfbS68LCQv8BsS+Nhtv2vLa/Cd6JiA+6jYS+0Gud6LV+TV5VYklvS1qPiLe6j4Q+0Gud6HU2NLnifl7SiqQXbX85/Xip41zoHr3WiV5nwK4vB4yIv0pq7Q+TYhjotU70Ohv4zUkASIbhBoBkGG4ASIbhBoBkGG4ASIbhBoBkGG4ASIbhBoBkGG4ASIbhBoBkGG4ASMYR0f5B7f9I+vc+DvFbSXdaijPLGX4fEb9rKwy9DiYDvdaZoXGvnQz3ftmeRMSYDOUztGkIj4cM7RvC45m1DDxVAgDJMNwAkMxQh/tC6QAiQxeG8HjI0L4hPJ6ZyjDI57gBAL9sqFfcAIBfMKjhtn3a9le2b9p+s1CGi7a/t3290PmP2f7E9rrtG7ZfL5GjbaW7pdduzHqv0wz9dxsRg/iQdEDSvyT9QdJBSX+XdKJAjhckPSfpeqH/hyckPTf9/HFJ/yzx/1Bbt/RKrzV1O6Qr7mVJNyPi64j4SdJ7kl7uO0REfCrph77Pu+P830XEtennP0palzQqlaclxbul107MfK/TDL13O6ThHkn6ZsftDeX/xt4X20uSnpX0edkk+0a3O9BrvfrqdkjD7Ud8bWZf8mL7MUnvS3ojIjZL59knup2i13r12e2QhntD0rEdt5+U9G2hLEXZntf2N8A7EfFB6TwtoFvRa8367nZIw/2FpKdtP2X7oKRXJH1YOFPvbFvS25LWI+Kt0nlaMvPd0mu9SnQ7mOGOiC1Jq5I+1vaT+3+OiBt957D9rqTPJD1je8P2az1HeF7SiqQXbX85/Xip5wytGkK39No+ev2f3rvlNycBIJnBXHEDAJphuAEgGYYbAJJhuAEgGYYbAJJhuAEgGYYbAJJhuAEgmf8C4CcOAm45hJMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                      [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29d94286550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNIST Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_3:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = img.reshape(-1,28,28,1) # image: 28 x 28 with 1 color\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01)) \n",
    "# 5 filters: 3 x 3 with 1 color - with random weights\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME') # output: 14 x 14\n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNIST Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_1:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# output: 7 x 7, subsampling\n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST CNN - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_2:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01)) # 32 filters\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_3:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01)) # 64 filters\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.354631212\n",
      "Epoch: 0002 cost = 0.098963875\n",
      "Epoch: 0003 cost = 0.070669603\n",
      "Epoch: 0004 cost = 0.058173028\n",
      "Epoch: 0005 cost = 0.049222966\n",
      "Epoch: 0006 cost = 0.042712224\n",
      "Epoch: 0007 cost = 0.038066180\n",
      "Epoch: 0008 cost = 0.033661400\n",
      "Epoch: 0009 cost = 0.029634245\n",
      "Epoch: 0010 cost = 0.026147703\n",
      "Epoch: 0011 cost = 0.023307886\n",
      "Epoch: 0012 cost = 0.019125698\n",
      "Epoch: 0013 cost = 0.019624088\n",
      "Epoch: 0014 cost = 0.016445075\n",
      "Epoch: 0015 cost = 0.013349670\n",
      "Learning Finished!\n",
      "Accuracy: 0.9871\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.384699068\n",
      "Epoch: 0002 cost = 0.090799233\n",
      "Epoch: 0003 cost = 0.071185579\n",
      "Epoch: 0004 cost = 0.055989090\n",
      "Epoch: 0005 cost = 0.051450080\n",
      "Epoch: 0006 cost = 0.043807679\n",
      "Epoch: 0007 cost = 0.041012813\n",
      "Epoch: 0008 cost = 0.037941040\n",
      "Epoch: 0009 cost = 0.035710613\n",
      "Epoch: 0010 cost = 0.033244250\n",
      "Epoch: 0011 cost = 0.029798216\n",
      "Epoch: 0012 cost = 0.029785311\n",
      "Epoch: 0013 cost = 0.028435096\n",
      "Epoch: 0014 cost = 0.025194520\n",
      "Epoch: 0015 cost = 0.027397320\n",
      "Learning Finished!\n",
      "Accuracy: 0.9934\n",
      "Label:  [8]\n",
      "Prediction:  [8]\n"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01)) # 32 filters\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01)) # 64 filters\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01)) # 64 filters\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "L3 = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Class, Layers, Ensemble\n",
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.490078974\n",
      "Epoch: 0002 cost = 0.103938772\n",
      "Epoch: 0003 cost = 0.073446491\n",
      "Epoch: 0004 cost = 0.062875915\n",
      "Epoch: 0005 cost = 0.052887349\n",
      "Epoch: 0006 cost = 0.047152937\n",
      "Epoch: 0007 cost = 0.041555877\n",
      "Epoch: 0008 cost = 0.039651411\n",
      "Epoch: 0009 cost = 0.036919533\n",
      "Epoch: 0010 cost = 0.034718311\n",
      "Epoch: 0011 cost = 0.032198803\n",
      "Epoch: 0012 cost = 0.028824529\n",
      "Epoch: 0013 cost = 0.030366254\n",
      "Epoch: 0014 cost = 0.025861976\n",
      "Epoch: 0015 cost = 0.025819187\n",
      "Learning Finished!\n",
      "Accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1 and Pooling Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1, rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #3 and Pooling Layer #3\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3, rate=0.3, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.290574072\n",
      "Epoch: 0002 cost = 0.088556266\n",
      "Epoch: 0003 cost = 0.066959710\n",
      "Epoch: 0004 cost = 0.059316052\n",
      "Epoch: 0005 cost = 0.049490565\n",
      "Epoch: 0006 cost = 0.045705229\n",
      "Epoch: 0007 cost = 0.042033737\n",
      "Epoch: 0008 cost = 0.040150302\n",
      "Epoch: 0009 cost = 0.034693183\n",
      "Epoch: 0010 cost = 0.035378141\n",
      "Epoch: 0011 cost = 0.031952403\n",
      "Epoch: 0012 cost = 0.031929293\n",
      "Epoch: 0013 cost = 0.028795217\n",
      "Epoch: 0014 cost = 0.028814836\n",
      "Epoch: 0015 cost = 0.027189408\n",
      "Learning Finished!\n",
      "Accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = [0.2839881  0.28876806 0.28335049 0.2904134  0.29190497 0.27617034\n",
      " 0.28361517]\n",
      "Epoch: 0002 cost = [0.08506936 0.08712376 0.09105948 0.08926679 0.09223241 0.08887489\n",
      " 0.09236921]\n",
      "Epoch: 0003 cost = [0.06654451 0.06386516 0.06582348 0.06793372 0.06789211 0.0673737\n",
      " 0.07254327]\n",
      "Epoch: 0004 cost = [0.05542082 0.05483889 0.05576156 0.05675056 0.05699331 0.05830432\n",
      " 0.05987501]\n",
      "Epoch: 0005 cost = [0.04843963 0.04880107 0.05084194 0.0508775  0.050397   0.05119998\n",
      " 0.052273  ]\n",
      "Epoch: 0006 cost = [0.04291666 0.0449258  0.04587443 0.04293705 0.04456073 0.04470681\n",
      " 0.04663384]\n",
      "Epoch: 0007 cost = [0.04157434 0.04082885 0.0409977  0.04125339 0.0412068  0.04197668\n",
      " 0.04270582]\n",
      "Epoch: 0008 cost = [0.03583655 0.0367612  0.03839342 0.03933353 0.03983586 0.03850048\n",
      " 0.03924675]\n",
      "Epoch: 0009 cost = [0.035774   0.03385644 0.03525927 0.03565701 0.03537486 0.0360568\n",
      " 0.03716643]\n",
      "Epoch: 0010 cost = [0.0342434  0.03471179 0.03329802 0.03224129 0.03323303 0.0336298\n",
      " 0.03527294]\n",
      "Epoch: 0011 cost = [0.0312292  0.03103046 0.03146707 0.0330221  0.03138848 0.03122388\n",
      " 0.0319674 ]\n",
      "Epoch: 0012 cost = [0.02953473 0.02911985 0.02989182 0.03105704 0.02996207 0.02880701\n",
      " 0.03154137]\n",
      "Epoch: 0013 cost = [0.02929886 0.02722023 0.02858433 0.02941699 0.0275854  0.02860226\n",
      " 0.03094792]\n",
      "Epoch: 0014 cost = [0.02694955 0.02847961 0.02818828 0.02811688 0.02700819 0.0288048\n",
      " 0.02970379]\n",
      "Epoch: 0015 cost = [0.0263122  0.02648085 0.0258888  0.02564297 0.0266021  0.02732778\n",
      " 0.02649399]\n",
      "Epoch: 0016 cost = [0.02343043 0.02466002 0.02664152 0.02784218 0.02631231 0.02536049\n",
      " 0.02602286]\n",
      "Epoch: 0017 cost = [0.02492439 0.02236879 0.0250915  0.0243839  0.0235911  0.02523481\n",
      " 0.02532881]\n",
      "Epoch: 0018 cost = [0.02521003 0.02482978 0.02310978 0.02554408 0.02534179 0.02525129\n",
      " 0.02512803]\n",
      "Epoch: 0019 cost = [0.02244063 0.02230886 0.02300841 0.02217352 0.02395932 0.02217195\n",
      " 0.02385906]\n",
      "Epoch: 0020 cost = [0.02323562 0.0210149  0.02399962 0.02174347 0.02325353 0.02364941\n",
      " 0.02329319]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "num_models = 7\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "    \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy: 0.9941\n",
      "1 Accuracy: 0.9933\n",
      "2 Accuracy: 0.9942\n",
      "3 Accuracy: 0.9935\n",
      "4 Accuracy: 0.9943\n",
      "5 Accuracy: 0.9946\n",
      "6 Accuracy: 0.9937\n",
      "Ensemble accuracy: 0.9954\n"
     ]
    }
   ],
   "source": [
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros([test_size, 10])\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root = './mnist_data/', train = True, \n",
    "                               transform = transforms.ToTensor(), download = True)\n",
    "test_dataset = datasets.MNIST(root = './mnist_data/', train = False,\n",
    "                             transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
    "        self.max1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.max2 = nn.MaxPool2d(2, 2)\n",
    "        self.l3 = nn.Linear(7*7*64, 10)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.l3.weight)\n",
    "        nn.init.normal_(self.l3.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.max1(self.relu(self.conv1(x)))\n",
    "        out2 = self.max2(self.relu(self.conv2(out1)))\n",
    "        out3 = self.l3(out2.reshape(batch_size, -1))\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tCost:  0.2851275027279429\n",
      "1 \tCost:  0.06936634214284515\n",
      "2 \tCost:  0.04970166616607461\n",
      "3 \tCost:  0.04021722561640976\n",
      "4 \tCost:  0.03355992239201442\n",
      "5 \tCost:  0.028252237746783048\n",
      "6 \tCost:  0.023792295577780682\n",
      "7 \tCost:  0.021015017036406777\n",
      "8 \tCost:  0.018010520548511242\n",
      "9 \tCost:  0.014878123990274628\n",
      "10 \tCost:  0.013685103401706625\n",
      "11 \tCost:  0.010974741839709173\n",
      "12 \tCost:  0.010290276678254788\n",
      "13 \tCost:  0.00852521916191715\n",
      "14 \tCost:  0.008914551474833077\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch_xs, batch_ys = batch\n",
    "        batch_xs = batch_xs.to(device)\n",
    "        batch_ys = batch_ys.to(device)\n",
    "        y_pred = model(batch_xs)\n",
    "        loss = criterion(y_pred, batch_ys)\n",
    "        avg_cost+= loss.item() / len(train_loader)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch, '\\tCost: ', avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.00 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    #images = images.view(-1, 28*28)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    accuracy = correct / float(total)\n",
    "print('Accuracy: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9901), 10000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
    "        self.max = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.max3 = nn.MaxPool2d(2, 2, padding = 1)\n",
    "        self.l4 = nn.Linear(4*4*128, 625)\n",
    "        self.l5 = nn.Linear(625, 10)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.l4.weight)\n",
    "        nn.init.xavier_uniform_(self.l5.weight)\n",
    "        nn.init.normal_(self.l4.bias)\n",
    "        nn.init.normal_(self.l5.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.dropout(self.max(self.relu(self.conv1(x))))\n",
    "        out2 = self.dropout(self.max(self.relu(self.conv2(out1))))\n",
    "        out3 = self.dropout(self.max3(self.relu(self.conv3(out2))))\n",
    "        out4 = self.dropout(self.l4(out3.reshape(-1, 128*4*4)))\n",
    "        out5 = self.l5(out4)\n",
    "        return out5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tCost:  0.35989776670932766\n",
      "1 \tCost:  0.09188959597765142\n",
      "2 \tCost:  0.06937137712491678\n",
      "3 \tCost:  0.06064453859386653\n",
      "4 \tCost:  0.05345056334704469\n",
      "5 \tCost:  0.05170544588007035\n",
      "6 \tCost:  0.046572755175487486\n",
      "7 \tCost:  0.04523211089971791\n",
      "8 \tCost:  0.042854295937383186\n",
      "9 \tCost:  0.04088595542882105\n",
      "10 \tCost:  0.03914517396168471\n",
      "11 \tCost:  0.037829466349600535\n",
      "12 \tCost:  0.037100330448399\n",
      "13 \tCost:  0.03489699520401092\n",
      "14 \tCost:  0.036678537246868134\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch_xs, batch_ys = batch\n",
    "        y_pred = model(batch_xs)\n",
    "        loss = criterion(y_pred, batch_ys)\n",
    "        avg_cost+= loss.item() / len(train_loader)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch, '\\tCost: ', avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "for images, labels in test_loader:\n",
    "    #images = images.view(-1, 28*28)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    accuracy = correct / total\n",
    "print('Accuracy: %d %%' % (100 * correct / total))\n",
    "print(correct, '/', total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self._build_net()\n",
    "    \n",
    "    def _build_net(self):\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(1, 32, 3, 1, 1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2, 2),\n",
    "                                    nn.Dropout(0.3))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2, 2), \n",
    "                                    nn.Dropout(0.3))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, 2, 1),\n",
    "                                   nn.Dropout(0.3))\n",
    "        self.l4 = nn.Linear(4*4*128, 625)\n",
    "        self.layer4 = nn.Sequential(self.l4,\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.5))\n",
    "        self.l5 = nn.Linear(625, 10)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.l4.weight)\n",
    "        nn.init.xavier_uniform_(self.l5.weight)\n",
    "        nn.init.normal_(self.l4.bias)\n",
    "        nn.init.normal_(self.l5.bias)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr = learning_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1)\n",
    "        out3 = self.layer3(out2)\n",
    "        out3 = out3.view(-1, 4*4*128)\n",
    "        out4 = self.layer4(out3)\n",
    "        out5 = self.l5(out4)\n",
    "        return out5\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        self.eval()\n",
    "        return self.forward(x_test)\n",
    "    \n",
    "    def get_accuracy(self, test_loader):\n",
    "        self.eval()\n",
    "        self.correct_predict = []\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch_xs, batch_ys = batch\n",
    "            batch_xs = batch_xs.to(device)\n",
    "            batch_ys = batch_ys.to(device)\n",
    "            predicted = self.predict(batch_xs)\n",
    "            correct = (torch.max(predicted.data, 1)[1] == batch_ys.data)\n",
    "            self.correct_predict.append(correct.float().mean())\n",
    "        return np.mean(self.correct_predict)\n",
    "    \n",
    "    def train_(self, x_data, y_data):\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        hypothesis = self.forward(x_data)\n",
    "        self.cost = self.criterion(hypothesis, y_data)\n",
    "        self.cost.backward()\n",
    "        self.optimizer.step()\n",
    "        return self.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tCost:  0.3535746435200172\n",
      "1 \tCost:  0.08811469525409243\n",
      "2 \tCost:  0.06842434870234375\n",
      "3 \tCost:  0.055755916054670986\n",
      "4 \tCost:  0.05097590289001042\n",
      "5 \tCost:  0.04590595108165873\n",
      "6 \tCost:  0.04178384645939026\n",
      "7 \tCost:  0.038287362835835635\n",
      "8 \tCost:  0.03609782751494399\n",
      "9 \tCost:  0.03253754068549214\n",
      "10 \tCost:  0.0346236768759263\n",
      "11 \tCost:  0.03090980921731291\n",
      "12 \tCost:  0.029206139987557753\n",
      "13 \tCost:  0.03000352736640099\n",
      "14 \tCost:  0.028421622673098106\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch_xs, batch_ys = batch\n",
    "        batch_xs = batch_xs.to(device)\n",
    "        batch_ys = batch_ys.to(device)\n",
    "        y_pred = model(batch_xs)\n",
    "        cost = model.train_(batch_xs, batch_ys)\n",
    "        avg_cost+= cost.item() / len(train_loader)\n",
    "        \n",
    "    print(epoch, '\\tCost: ', avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.27 %\n",
      "tensor(9927, device='cuda:0') / 10000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "for images, labels in test_loader:\n",
    "    #images = images.view(-1, 28*28)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    accuracy = correct / float(total)\n",
    "print('Accuracy: %.2f %%' % (100 * float(correct )/ float(total)))\n",
    "print(correct, '/', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', model.get_accuracy(test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
